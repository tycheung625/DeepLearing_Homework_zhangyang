import streamlit as st
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import matplotlib.dates as mdates
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from streamlit.components.v1 import html
st.set_page_config(
    page_title="å¤©æ°”é¢„æµ‹",
    page_icon="ğŸ§Š",
    layout="centered",
    initial_sidebar_state="auto",
)
# å®šä¹‰æ¸©åº¦é¢„æµ‹æ¨¡å‹
class TemperaturePredictor(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):
        super(TemperaturePredictor, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size1)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size1, hidden_size2)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden_size2, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        x = self.fc2(x)
        x = self.relu2(x)
        x = self.fc3(x)
        return x

# å®šä¹‰RNNæ¨¡å‹
class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers):
        super(RNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        out = self.fc(out[:, -1, :])
        return out

def trainliner(_col1, _col2):
	# è¯»å–æ•°æ®
	data = pd.read_csv('beijing2.csv')

	# æå–ç‰¹å¾å’Œæ ‡ç­¾
	features = data[['date', 'æœ€é«˜æ¸©åº¦', 'æœ€ä½æ¸©åº¦']]
	temperature_labels = data[['æœ€é«˜æ¸©åº¦', 'æœ€ä½æ¸©åº¦']]
	air_quality_labels = data['ç©ºæ°”è´¨é‡'].astype(float)  # å°†ç©ºæ°”è´¨é‡åˆ—è½¬æ¢ä¸ºæµ®ç‚¹æ•°

	# å°†æ—¥æœŸè½¬æ¢ä¸ºå¤©æ•°ï¼Œä½œä¸ºä¸€ä¸ªç®€å•çš„ç‰¹å¾
	features['date'] = features['date'].apply(lambda x: (datetime.strptime(x, "%Y/%m/%d") - datetime(1970, 1, 1)).days)

	# æ•°æ®é¢„å¤„ç†
	scaler = StandardScaler()
	features_scaled = scaler.fit_transform(features)

	# é€‰æ‹©å›ºå®šçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†
	split_index = int(0.9 * len(features))

	X_train = features_scaled[:split_index]
	temp_y_train = temperature_labels[:split_index]
	air_y_train = air_quality_labels[:split_index]
	dates_train = features['date'][:split_index]

	X_test = features_scaled[split_index:]
	temp_y_test = temperature_labels[split_index:]
	air_y_test = air_quality_labels[split_index:]
	dates_test = features['date'][split_index:]

	# è½¬æ¢ä¸º PyTorch å¼ é‡
	X_train_tensor = torch.FloatTensor(X_train)
	X_test_tensor = torch.FloatTensor(X_test)
	temp_y_train_tensor = torch.FloatTensor(temp_y_train.values)
	temp_y_test_tensor = torch.FloatTensor(temp_y_test.values)
	air_y_train_tensor = torch.FloatTensor(air_y_train.values)
	air_y_test_tensor = torch.FloatTensor(air_y_test.values)
	# åˆå§‹åŒ–æ¸©åº¦é¢„æµ‹æ¨¡å‹
	temp_input_size = len(features.columns)
	temp_hidden_size1 = 128
	temp_hidden_size2 = 64
	temp_output_size = 2  # è¾“å‡ºä¸º2ä¸ªå€¼ï¼Œå³æœ€é«˜æ¸©åº¦å’Œæœ€ä½æ¸©åº¦
	temperature_model = TemperaturePredictor(temp_input_size, temp_hidden_size1, temp_hidden_size2, temp_output_size)

	# å®šä¹‰æ¸©åº¦é¢„æµ‹æ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
	temp_criterion = nn.MSELoss()
	temp_optimizer = torch.optim.Adam(temperature_model.parameters(), lr=0.001)
	
	
	# è®­ç»ƒæ¸©åº¦é¢„æµ‹æ¨¡å‹
	num_epochs = 600
    
	output_table = col1.dataframe()
	chart_container = col2.empty()
	for epoch in range(num_epochs):
		temp_outputs = temperature_model(X_train_tensor)
		temp_loss = temp_criterion(temp_outputs, temp_y_train_tensor)
        
		temp_optimizer.zero_grad()
		temp_loss.backward()
		temp_optimizer.step()

		if (epoch + 1) % 10 == 0:
			# å°†è®­ç»ƒç»“æœåˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ·»åŠ åˆ°è¡¨æ ¼æ•°æ®åˆ—è¡¨
			row_data = f'Epoch [{epoch+1}/{num_epochs}]ï¼ŒLossï¼š{temp_loss.item():.4f}'
			table_data.append(row_data)

			# ä½¿ç”¨è¿”å›å€¼æ›´æ–°è¡¨æ ¼æ•°æ®æº
			output_table.dataframe(table_data)

			# æ›´æ–°æŸå¤±æ›²çº¿
			loss_curve.set_xdata(range(1, epoch + 2, 10))
			loss_curve.set_ydata([float(data.split('ï¼š')[-1]) for data in table_data])
			ax.set_ylabel('Loss')
			ax.legend(['Loss'])
			ax.relim()
			ax.autoscale_view()

			
			with chart_container:
				st.pyplot(fig)
	torch.save(temperature_model.state_dict(), 'temperature_model.pth')

def train_rnn(_col1, _col2):
	
	data = pd.read_csv('beijing2.csv')
	data['date'] = pd.to_datetime(data['date'])
	data = data.set_index('date')


	# é€‰å–æœ€é«˜æ¸©åº¦å’Œæœ€ä½æ¸©åº¦ä½œä¸ºé¢„æµ‹ç›®æ ‡
	target_cols = ['æœ€é«˜æ¸©åº¦', 'æœ€ä½æ¸©åº¦']
	data = data[target_cols]

	# æ•°æ®é¢„å¤„ç†
	scaler = MinMaxScaler()
	data_scaled = scaler.fit_transform(data)

	# åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
	train_size = int(len(data) * 0.8)
	train_data, test_data = data_scaled[0:train_size], data_scaled[train_size:]

	

	def create_sequences(data, seq_length):
		sequences = []
		targets = []
		dates = []
		for i in range(len(data) - seq_length):
			seq = data[i:i + seq_length]
			target = data[i + seq_length:i + seq_length + 1].flatten()
			date_index = i + seq_length
			date = data[date_index,0]
			sequences.append(seq)
			targets.append(target)
			dates.append(date)
		return torch.tensor(sequences), torch.tensor(targets), dates
    
	seq_length = 15

	X_train, y_train, train_dates = create_sequences(train_data, seq_length)
	X_test, y_test, test_dates = create_sequences(test_data, seq_length)
    # åˆå§‹åŒ– RNN æ¨¡å‹
	rnn_input_size = len(target_cols)
	rnn_hidden_size = 128
	rnn_output_size = len(target_cols)
	rnn_num_layers = 3
	rnn_model = RNN(rnn_input_size, rnn_hidden_size, rnn_output_size, rnn_num_layers)

    
	rnn_criterion = nn.MSELoss()
	rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)

	
	device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
	X_train_rnn, y_train_rnn = X_train.to(device), y_train.to(device)
	X_test_rnn, y_test_rnn = X_test.to(device), y_test.to(device)
	rnn_model.to(device)

    # è®­ç»ƒ RNN æ¨¡å‹
	num_epochs = 300
	output_table = col1.dataframe()
	chart_container = col2.empty()
    
	for epoch in range(num_epochs):
		rnn_outputs = rnn_model(X_train_rnn.float())
		rnn_loss = rnn_criterion(rnn_outputs, y_train_rnn.float())
        
		rnn_optimizer.zero_grad()
		rnn_loss.backward()
		rnn_optimizer.step()

		if (epoch + 1) % 10 == 0:
			row_data = f'Epoch [{epoch+1}/{num_epochs}], Loss: {rnn_loss.item():.4f}'
			table_data.append(row_data)
			output_table.dataframe(table_data)

            # æ›´æ–°æŸå¤±æ›²çº¿
			loss_curve.set_xdata(range(1, epoch + 2, 10))
			loss_curve.set_ydata([float(data.split(':')[1]) for data in table_data])
			ax.set_ylabel('Loss')
			ax.legend(['Loss'])
			ax.relim()
			ax.autoscale_view()

            
			with chart_container:
				st.pyplot(fig)

	torch.save(rnn_model.state_dict(), 'rnn_model.pth')
class upname:
    def __init__(self, name):
        self.name = name
if __name__ == '__main__':
	
	st.title('æ¨¡å‹è®­ç»ƒ')
	option=st.sidebar.selectbox('æ–¹æ³•:',('Linear','RNN'))
	
	train_button = st.sidebar.button('è®­ç»ƒæ¸©åº¦é¢„æµ‹æ¨¡å‹')

	
	table_data = []

	
	fig, ax = plt.subplots()
	loss_curve, = ax.plot([], [], label='æŸå¤±æ›²çº¿')
	ax.set_xlabel('Epoch')
	ax.set_ylabel('æŸå¤±')
	ax.legend()
	
	chart_container = st.container()

	
	col1, col2 = st.columns(2)
	col1.info("Epochs loss:")
	col2.info("Loss curve:")
	
	table_data = []

	if train_button:
		if option=='Linear':
			trainliner(col1, col2)
			col1.success("è®­ç»ƒå®Œæˆ")
		if option=='RNN':
			train_rnn(col1, col2)
			col1.success("è®­ç»ƒå®Œæˆ")
